"""
domain_adaptation.py - Domain Adaptation (PPG â†’ rPPG) ëª¨ë“ˆ

Phase 3-1: Domain Adaptation í•™ìŠµ

ëª©í‘œ: PPG ëª¨ë¸ì„ rPPG ë°ì´í„°ë¡œ fine-tuning
- Pre-trained ResNet ë¡œë“œ
- ë§ˆì§€ë§‰ ë ˆì´ì–´ unfreeze
- rPPG ë°ì´í„°ë¡œ fine-tuning
- ëª¨ë¸ ì €ì¥
"""

import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

import h5py
import numpy as np
import tensorflow as tf
import tensorflow.keras as ks
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from kapre import STFT, Magnitude, MagnitudeToDecibel
import argparse
import json


def load_pretrained_model(model_path):
    """
    Pre-trained PPG ëª¨ë¸ ë¡œë“œ
    
    Args:
        model_path: ëª¨ë¸ ê²½ë¡œ (e.g., data/resnet_ppg_nonmixed.h5)
    
    Returns:
        model: Keras ëª¨ë¸
    """
    print(f"\nğŸ”„ Pre-trained ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    
    dependencies = {
        'ReLU': ks.layers.ReLU,
        'STFT': STFT,
        'Magnitude': Magnitude,
        'MagnitudeToDecibel': MagnitudeToDecibel
    }
    
    model = ks.models.load_model(model_path, custom_objects=dependencies)
    print(f"   âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print(f"   ì…ë ¥ í˜•íƒœ: {model.input_shape}")
    print(f"   ì¶œë ¥ í˜•íƒœ: {model.output_shape}")
    print(f"   ì´ íŒŒë¼ë¯¸í„°: {model.count_params():,}")
    
    return model


def freeze_base_layers(model, num_unfreeze=3):
    """
    ê¸°ë³¸ ë ˆì´ì–´ ë™ê²° (ì „ì´ í•™ìŠµìš©)
    
    Args:
        model: Keras ëª¨ë¸
        num_unfreeze: ë§ˆì§€ë§‰ì—ì„œ unfreezeí•  ë ˆì´ì–´ ìˆ˜
    
    Returns:
        model: ìˆ˜ì •ëœ ëª¨ë¸
    """
    print(f"\nâ„ï¸ ê¸°ë³¸ ë ˆì´ì–´ ë™ê²° ì¤‘ (ë§ˆì§€ë§‰ {num_unfreeze}ê°œ ì œì™¸)")
    
    # ëª¨ë“  ë ˆì´ì–´ ë™ê²°
    for layer in model.layers[:-num_unfreeze]:
        layer.trainable = False
    
    # ë§ˆì§€ë§‰ num_unfreeze ë ˆì´ì–´ í™œì„±í™”
    for layer in model.layers[-num_unfreeze:]:
        layer.trainable = True
    
    # ë™ê²° ìƒíƒœ í™•ì¸
    trainable_count = sum([1 for layer in model.layers if layer.trainable])
    frozen_count = sum([1 for layer in model.layers if not layer.trainable])
    
    print(f"   Trainable ë ˆì´ì–´: {trainable_count}")
    print(f"   Frozen ë ˆì´ì–´: {frozen_count}")
    print(f"   Trainable íŒŒë¼ë¯¸í„°: {model.count_params():,}")
    
    return model


def load_rppg_data(data_dir='data'):
    """
    ë¶„í• ëœ rPPG ë°ì´í„° ë¡œë“œ
    
    Args:
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
    
    Returns:
        train_x, train_y, val_x, val_y, test_x, test_y
    """
    print(f"\nğŸ“‚ rPPG ë°ì´í„° ë¡œë“œ ì¤‘")
    
    # Train
    with h5py.File(f'{data_dir}/rppg_train.h5', 'r') as f:
        train_x = f['signals'][:]
        train_y = f['labels'][:]
    
    # Val
    with h5py.File(f'{data_dir}/rppg_val.h5', 'r') as f:
        val_x = f['signals'][:]
        val_y = f['labels'][:]
    
    # Test
    with h5py.File(f'{data_dir}/rppg_test.h5', 'r') as f:
        test_x = f['signals'][:]
        test_y = f['labels'][:]
    
    print(f"   Train: {train_x.shape[0]} ìƒ˜í”Œ")
    print(f"   Val:   {val_x.shape[0]} ìƒ˜í”Œ")
    print(f"   Test:  {test_x.shape[0]} ìƒ˜í”Œ")
    
    # ì‹ í˜¸ í˜•íƒœ í™•ì¸ ë° ì¡°ì •
    print(f"   ì‹ í˜¸ í˜•íƒœ: {train_x.shape}")
    print(f"   ë ˆì´ë¸” í˜•íƒœ: {train_y.shape}")
    
    # ì‹ í˜¸ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜ (N, 875) â†’ (N, 875, 1)
    if len(train_x.shape) == 2:
        train_x = train_x[:, :, np.newaxis]
        val_x = val_x[:, :, np.newaxis]
        test_x = test_x[:, :, np.newaxis]
        print(f"   ë³€í™˜ í›„ ì‹ í˜¸ í˜•íƒœ: {train_x.shape}")
    
    return train_x, train_y, val_x, val_y, test_x, test_y


def compile_model(model, learning_rate=0.001):
    """
    ëª¨ë¸ ì»´íŒŒì¼
    
    Args:
        model: Keras ëª¨ë¸
        learning_rate: í•™ìŠµë¥ 
    
    Returns:
        model: ì»´íŒŒì¼ëœ ëª¨ë¸
    """
    print(f"\nâš™ï¸ ëª¨ë¸ ì»´íŒŒì¼ (í•™ìŠµë¥ : {learning_rate})")
    
    optimizer = Adam(learning_rate=learning_rate)
    
    # ëª¨ë¸ ì¶œë ¥ ê°œìˆ˜ì— ë”°ë¼ ì†ì‹¤í•¨ìˆ˜ ê²°ì •
    if isinstance(model.output, list):
        # ì—¬ëŸ¬ ì¶œë ¥ (e.g., [SBP, DBP])
        loss = ['mse', 'mse']
    else:
        loss = 'mse'
    
    model.compile(
        optimizer=optimizer,
        loss=loss,
        metrics=['mae']
    )
    
    print(f"   âœ“ ì»´íŒŒì¼ ì™„ë£Œ")
    
    return model


def train_domain_adaptation(model, train_x, train_y, val_x, val_y,
                           epochs=50, batch_size=32, output_dir='models'):
    """
    Domain adaptation í•™ìŠµ
    
    Args:
        model: ì»´íŒŒì¼ëœ ëª¨ë¸
        train_x, train_y: í•™ìŠµ ë°ì´í„°
        val_x, val_y: ê²€ì¦ ë°ì´í„°
        epochs: ì—í¬í¬ ìˆ˜
        batch_size: ë°°ì¹˜ í¬ê¸°
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    
    Returns:
        history: í•™ìŠµ ì´ë ¥
        best_model_path: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê²½ë¡œ
    """
    print(f"\nğŸ“ Domain Adaptation í•™ìŠµ ì¤‘...")
    print(f"   Epochs: {epochs}, Batch size: {batch_size}")
    
    os.makedirs(output_dir, exist_ok=True)
    
    best_model_path = os.path.join(output_dir, 'resnet_rppg_adapted.h5')
    
    # ì½œë°± ì •ì˜
    callbacks = [
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        ModelCheckpoint(
            best_model_path,
            monitor='val_loss',
            save_best_only=True,
            verbose=1,
            mode='min'
        ),
        # Early stopping
        EarlyStopping(
            monitor='val_loss',
            patience=10,
            restore_best_weights=True,
            verbose=1
        ),
        # í•™ìŠµë¥  ê°ì†Œ
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-6,
            verbose=1
        )
    ]
    
    # í•™ìŠµ
    history = model.fit(
        train_x, train_y,
        validation_data=(val_x, val_y),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=callbacks,
        verbose=1
    )
    
    print(f"\n   âœ“ í•™ìŠµ ì™„ë£Œ")
    print(f"   ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_path}")
    
    return history, best_model_path


def evaluate_model(model, test_x, test_y):
    """
    ëª¨ë¸ í‰ê°€
    
    Args:
        model: Keras ëª¨ë¸
        test_x, test_y: í…ŒìŠ¤íŠ¸ ë°ì´í„°
    """
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì…‹ í‰ê°€")
    
    # í‰ê°€
    results = model.evaluate(test_x, test_y, verbose=0)
    
    if isinstance(results, list):
        # ì—¬ëŸ¬ ì¶œë ¥
        print(f"   Loss (SBP): {results[0]:.4f}")
        print(f"   Loss (DBP): {results[1]:.4f}")
        print(f"   MAE (SBP): {results[2]:.4f} mmHg")
        print(f"   MAE (DBP): {results[3]:.4f} mmHg")
    else:
        print(f"   Loss: {results[0]:.4f}")
        print(f"   MAE: {results[1]:.4f}")
    
    # ì˜ˆì¸¡
    predictions = model.predict(test_x, verbose=0)
    
    if isinstance(predictions, list):
        pred_sbp = predictions[0].flatten()
        pred_dbp = predictions[1].flatten()
        true_sbp = test_y[:, 0]
        true_dbp = test_y[:, 1]
        
        mae_sbp = np.mean(np.abs(pred_sbp - true_sbp))
        mae_dbp = np.mean(np.abs(pred_dbp - true_dbp))
        
        print(f"\n   í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE):")
        print(f"   SBP: {mae_sbp:.2f} mmHg")
        print(f"   DBP: {mae_dbp:.2f} mmHg")
        
        # ê°œì„ ë„ (ê¸°ì¡´ PPG ëª¨ë¸ vs ì ì‘ ëª¨ë¸)
        # ê¸°ì¡´ PPG ëª¨ë¸ì˜ ì˜ˆìƒ ì„±ëŠ¥: SBP MAE ~28.9, DBP MAE ~15.2
        ppg_mae_sbp = 28.9
        ppg_mae_dbp = 15.2
        
        improvement_sbp = (ppg_mae_sbp - mae_sbp) / ppg_mae_sbp * 100
        improvement_dbp = (ppg_mae_dbp - mae_dbp) / ppg_mae_dbp * 100
        
        print(f"\n   PPG ëŒ€ë¹„ ê°œì„ ë„:")
        print(f"   SBP: {improvement_sbp:+.1f}% (ê¸°ì¡´: {ppg_mae_sbp:.2f} â†’ ê°œì„ : {mae_sbp:.2f})")
        print(f"   DBP: {improvement_dbp:+.1f}% (ê¸°ì¡´: {ppg_mae_dbp:.2f} â†’ ê°œì„ : {mae_dbp:.2f})")


def save_training_info(output_dir, history, best_model_path):
    """
    í•™ìŠµ ì •ë³´ ì €ì¥
    
    Args:
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        history: í•™ìŠµ ì´ë ¥
        best_model_path: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê²½ë¡œ
    """
    info_file = os.path.join(output_dir, 'training_info.json')
    
    info = {
        'model': 'ResNet (PPG â†’ rPPG Domain Adaptation)',
        'best_model': best_model_path,
        'epochs_trained': len(history.history['loss']),
        'best_epoch': np.argmin(history.history['val_loss']) + 1,
        'final_train_loss': float(history.history['loss'][-1]),
        'final_val_loss': float(history.history['val_loss'][-1]),
        'best_val_loss': float(np.min(history.history['val_loss'])),
        'history': {
            'train_loss': [float(x) for x in history.history['loss']],
            'val_loss': [float(x) for x in history.history['val_loss']]
        }
    }
    
    with open(info_file, 'w') as f:
        json.dump(info, f, indent=2)
    
    print(f"\n   âœ“ í•™ìŠµ ì •ë³´ ì €ì¥: {info_file}")


def main():
    parser = argparse.ArgumentParser(description='Domain Adaptation í•™ìŠµ')
    parser.add_argument('--pretrained', type=str,
                       default='data/resnet_ppg_nonmixed.h5',
                       help='Pre-trained ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--data-dir', type=str, default='data',
                       help='ë°ì´í„° ë””ë ‰í† ë¦¬')
    parser.add_argument('--epochs', type=int, default=50,
                       help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--learning-rate', type=float, default=0.001,
                       help='í•™ìŠµë¥ ')
    parser.add_argument('--output-dir', type=str, default='models',
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    print("\n" + "="*60)
    print("Domain Adaptation: PPG â†’ rPPG")
    print("="*60)
    
    # 1. ëª¨ë¸ ë¡œë“œ
    model = load_pretrained_model(args.pretrained)
    
    # 2. ê¸°ë³¸ ë ˆì´ì–´ ë™ê²°
    model = freeze_base_layers(model, num_unfreeze=3)
    
    # 3. ë°ì´í„° ë¡œë“œ
    train_x, train_y, val_x, val_y, test_x, test_y = load_rppg_data(args.data_dir)
    
    # 4. ëª¨ë¸ ì»´íŒŒì¼
    model = compile_model(model, learning_rate=args.learning_rate)
    
    # 5. í•™ìŠµ
    history, best_model_path = train_domain_adaptation(
        model, train_x, train_y, val_x, val_y,
        epochs=args.epochs,
        batch_size=args.batch_size,
        output_dir=args.output_dir
    )
    
    # 6. í‰ê°€
    evaluate_model(model, test_x, test_y)
    
    # 7. ì •ë³´ ì €ì¥
    save_training_info(args.output_dir, history, best_model_path)
    
    print("\n" + "="*60)
    print("âœ… Domain Adaptation í•™ìŠµ ì™„ë£Œ!")
    print("="*60)
    print(f"\në‹¤ìŒ ë‹¨ê³„:")
    print(f"  1. ëª¨ë¸ í‰ê°€: camera_rppg_advanced.py --model {best_model_path}")
    print(f"  2. GitHub commit: git add -A && git commit -m 'Phase 3-1: Domain Adaptation'")


if __name__ == '__main__':
    main()
