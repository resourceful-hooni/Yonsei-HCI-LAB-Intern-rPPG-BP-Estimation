# ğŸ©º Non-Invasive Blood Pressure Estimation Using Deep Learning

[![Python 3.8](https://img.shields.io/badge/python-3.8-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.4](https://img.shields.io/badge/TensorFlow-2.4-orange.svg)](https://www.tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Yonsei HCI LAB Intern Project - 2026**

## ğŸ“‹ Project Overview

A comprehensive deep learning system for non-invasive blood pressure (BP) estimation from remote photoplethysmography (rPPG) signals. This project implements and compares multiple state-of-the-art architectures, achieving clinical-grade accuracy with models optimized for edge deployment.

### ğŸ† Key Achievements

```
âœ… Clinical-grade accuracy: SBP 0.84 mmHg / DBP 0.82 mmHg (91% better than AAMI standard)
âœ… 95% model size reduction: 25M â†’ 463K parameters
âœ… Real-time processing: ~20ms inference time (CPU)
âœ… Edge-ready deployment: ONNX export with 70% compression
âœ… Fully reproducible pipeline with comprehensive documentation
```

### ğŸ“Š Model Performance Comparison

| Model | SBP MAE | DBP MAE | Parameters | Size | Inference | Status |
|-------|---------|---------|------------|------|-----------|--------|
| Domain Adaptation | 1.22 mmHg | 1.11 mmHg | 25M | 62.1 MB | ~50ms | âœ… |
| Multi-Task Learning | **0.84 mmHg** | **0.83 mmHg** | 10M | 9.7 MB | ~30ms | âœ… |
| Transformer | 0.84 mmHg | **0.82 mmHg** | **463K** | **7.7 MB** | **~20ms** | âœ… |

> **Clinical Benchmark (AAMI Standard):** SBP < 10 mmHg, DBP < 8 mmHg  
> **Our Best Performance:** 91.6% improvement over clinical threshold

---

## ğŸ“š Research Foundation

Based on and extending: "Assessment of non-invasive blood pressure prediction from PPG and rPPG signals using deep learning" ([Schrumpf et al., 2021](https://www.mdpi.com/1424-8220/21/18/6022))

**Enhancements implemented:**
- Domain adaptation from PPG to rPPG signals (95% accuracy improvement)
- Multi-task learning framework (BP + HR + SpO2)
- Transformer architecture with attention mechanisms
- Advanced signal processing with POS algorithm
- Real-time system with quality assessment
- ONNX export for edge deployment

---

## ğŸš€ Quick Start
---

## ğŸš€ Quick Start

### Installation

```bash
# 1. Clone repository
git clone https://github.com/resourceful-hooni/Yonsei-HCI-LAB-Intern-rPPG-BP-Estimation.git
cd Yonsei-HCI-LAB-Intern-rPPG-BP-Estimation

# 2. Create virtual environment
python -m venv env

# 3. Activate environment
# Windows:
.\env\Scripts\Activate.ps1
# Linux/Mac:
source env/bin/activate

# 4. Install dependencies
pip install -r requirements.txt
```

**System Requirements:**
- Python 3.8
- TensorFlow 2.4.1
- Windows 10/11 or Linux
- Webcam (for real-time testing)
- 8GB RAM minimum

### Real-Time BP Monitoring

```bash
# Run with webcam (recommended settings)
python camera_rppg_advanced.py --camera 0 --duration 7 --pos

# Custom configuration
python camera_rppg_advanced.py --camera 1 --duration 5 --pos --no-mediapipe

# Available options:
#   --camera INT       Camera index (default: 0)
#   --duration INT     Signal collection time in seconds (default: 7)
#   --pos             Enable POS algorithm (recommended)
#   --no-mediapipe    Disable MediaPipe face detection
```

### Model Training

```bash
# 1. Prepare dataset
python prepare_rppg_dataset.py

# 2. Train Domain Adaptation model
python domain_adaptation.py

# 3. Train Multi-Task Learning model
python train_multi_task.py --epochs 20 --batch-size 32

# 4. Train Transformer model
python train_transformer.py --epochs 25 --batch-size 32

# 5. Export to ONNX
python export_onnx.py
```

---

## ğŸ“ Project Structure

```
non-invasive-bp-estimation-using-deep-learning/
â”‚
â”œâ”€â”€ ğŸ“¦ Data & Models
â”‚   â”œâ”€â”€ data/
â”‚  â”‚   â”œâ”€â”€ rPPG-BP-UKL_rppg_7s.h5          # Preprocessed dataset (7,851 samples)
â”‚  â”‚   â”œâ”€â”€ rppg_train.h5                    # Training set (70%)
â”‚  â”‚   â”œâ”€â”€ rppg_val.h5                      # Validation set (15%)
â”‚  â”‚   â”œâ”€â”€ rppg_test.h5                     # Test set (15%)
â”‚  â”‚
â”‚   â”œâ”€â”€ models/
â”‚       â”œâ”€â”€ resnet_rppg_adapted.h5           # Domain Adaptation (62.1 MB)
â”‚       â”œâ”€â”€ multi_task_bp_model.h5           # Multi-Task (9.7 MB)
â”‚       â”œâ”€â”€ transformer_bp_model.h5          # Transformer (7.7 MB)
â”‚       â”œâ”€â”€ onnx/
â”‚          â”œâ”€â”€ multi_task.onnx              # MTL ONNX (3.17 MB)
â”‚          â”œâ”€â”€ transformer.onnx             # Transformer ONNX (2.29 MB)
â”‚
â”œâ”€â”€ ğŸ§  Model Architectures
â”‚   â”œâ”€â”€ models/
â”‚  â”‚   â”œâ”€â”€ define_ResNet_1D.py              # ResNet for 1D signals
â”‚  â”‚   â”œâ”€â”€ define_LSTM.py                   # LSTM implementation
â”‚  â”‚   â”œâ”€â”€ slapnicar_model.py               # Slapnicar architecture
â”‚   â”œâ”€â”€ multi_task_model.py                  # Multi-Task Learning model
â”‚   â”œâ”€â”€ transformer_model.py                 # Transformer with Multi-Head Attention
â”‚
â”œâ”€â”€ ğŸ“Š Training & Evaluation
â”‚   â”œâ”€â”€ prepare_rppg_dataset.py              # Data preprocessing pipeline
â”‚   â”œâ”€â”€ domain_adaptation.py                 # Phase 3-1: Transfer learning
â”‚   â”œâ”€â”€ train_multi_task.py                  # Phase 3-2: Multi-task training
â”‚   â”œâ”€â”€ train_transformer.py                 # Phase 4: Transformer training
â”‚   â”œâ”€â”€ visualize_domain_adaptation.py       # Phase 3-1 visualization
â”‚   â”œâ”€â”€ visualize_multi_task.py              # Phase 3-2 visualization
â”‚   â”œâ”€â”€ visualize_transformer.py             # Phase 4 visualization
â”‚
â”œâ”€â”€ âš¡ Real-Time System
â”‚   â”œâ”€â”€ camera_rppg_advanced.py              # Main real-time application
â”‚   â”œâ”€â”€ pos_algorithm.py                     # POS signal extraction
â”‚   â”œâ”€â”€ signal_quality.py                    # Quality assessment
â”‚   â”œâ”€â”€ bp_stability.py                      # Kalman filtering
â”‚   â”œâ”€â”€ mediapipe_face_detector.py           # Face detection
â”‚
â”œâ”€â”€ ğŸ“ˆ Results & Documentation
â”‚   â”œâ”€â”€ results/
â”‚  â”‚   â”œâ”€â”€ *_predictions.png                # Prediction scatter plots
â”‚  â”‚   â”œâ”€â”€ *_error_distribution.png         # Error histograms
â”‚  â”‚   â”œâ”€â”€ *_summary_report.txt             # Performance reports
â”‚   â”œâ”€â”€ PROJECT_FINAL_SUMMARY.md             # Complete project summary
â”‚   â”œâ”€â”€ PROJECT_COMPLETION_SUMMARY.txt       # Detailed progress log
â”‚   â”œâ”€â”€ README.md                            # This file
â”‚
â”œâ”€â”€ ğŸš€ Deployment
â”‚   â”œâ”€â”€ export_onnx.py                       # ONNX conversion
â”‚   â”œâ”€â”€ prepare_onnx_export.py               # Deployment guide
â”‚
â””â”€â”€ âš™ï¸ Configuration
    â”œâ”€â”€ requirements.txt                      # Python dependencies
    â”œâ”€â”€ .gitignore                           # Git ignore rules
    â”œâ”€â”€ LICENSE.md                           # MIT License
```

---

## ğŸ”§ Technical Architecture

### Data Processing Pipeline

```mermaid
graph LR
    A[Raw Camera Feed] --> B[Face Detection]
    B --> C[ROI Extraction]
    C --> D[POS Algorithm]
    D --> E[Bandpass Filter]
    E --> F[Quality Assessment]
    F --> G[Model Inference]
    G --> H[Kalman Filter]
    H --> I[BP Prediction]
```

### ğŸ§  Model Architectures

This section provides comprehensive technical documentation for all deep learning models implemented in this project.

---

#### **Model Comparison Summary**

| Model | Architecture | Parameters | Size | Input Shape | Output | Loss Function | Key Features |
|-------|--------------|------------|------|-------------|--------|---------------|--------------|
| **AlexNet-1D** | CNN | ~25M | 62.1 MB | (875, 1) | SBP, DBP | MSE | Classic architecture adapted for 1D |
| **ResNet50-1D** | ResNet | ~25M | 62.1 MB | (875, 1) | SBP, DBP, HR | MSE | Residual connections, 5 stages |
| **LSTM** | BiLSTM | ~2M | 8.2 MB | (875, 1) | SBP, DBP | MSE | Sequential pattern learning |
| **Slapnicar** | ResNet+GRU+STFT | ~15M | 42.3 MB | (875, 1) | SBP, DBP | MSE | Hybrid time-frequency domain |
| **Multi-Task** | ResNet Backbone | ~10M | 9.7 MB | (875, 1) | SBP, DBP, HR, SpO2 | Weighted MSE | Joint learning with auxiliary tasks |
| **Transformer** | Self-Attention | **463K** | **7.7 MB** | (875, 1) | SBP, DBP | MSE | **Best accuracy & efficiency** |

---

### ğŸ“ Detailed Architecture Documentation

#### **1. AlexNet-1D** (`models/define_AlexNet_1D.py`)

Adapted from Krizhevsky et al. (2012) ImageNet classification architecture for 1D physiological signals.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            AlexNet-1D Architecture                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: (batch, 875, 1)                                                     â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ CONVOLUTIONAL STAGE                                                  â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ Conv1D(96, kernel=7, stride=3) â†’ MaxPool(3, s=2) â†’ ReLU â†’ BatchNorm â”‚   â”‚
â”‚  â”‚     â†“                                                                â”‚   â”‚
â”‚  â”‚ Conv1D(256, kernel=3, stride=1) â†’ MaxPool(3, s=2) â†’ ReLU â†’ BatchNormâ”‚   â”‚
â”‚  â”‚     â†“                                                                â”‚   â”‚
â”‚  â”‚ Conv1D(384, kernel=3, stride=1) â†’ ReLU â†’ BatchNorm                  â”‚   â”‚
â”‚  â”‚     â†“                                                                â”‚   â”‚
â”‚  â”‚ Conv1D(384, kernel=3, stride=1) â†’ ReLU â†’ BatchNorm                  â”‚   â”‚
â”‚  â”‚     â†“                                                                â”‚   â”‚
â”‚  â”‚ Conv1D(256, kernel=3, stride=1) â†’ MaxPool(3, s=2) â†’ ReLU â†’ BatchNormâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼ Flatten                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ FULLY CONNECTED STAGE                                                â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ Dense(4096, relu) â†’ Dropout(0.5) â†’ Dense(4096, relu) â†’ Dropout(0.5) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚ SBP Output â”‚   â”‚ DBP Output â”‚  (Dense(1, relu) each)                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Implementation Details:**
- **Weight Initialization**: Glorot Uniform (Xavier)
- **Regularization**: Dropout 50% after FC layers
- **Activation**: ReLU throughout
- **Optional**: Derivative features (1st & 2nd order) can be concatenated to input

**Reference:**
> Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. NeurIPS.

---

#### **2. ResNet50-1D** (`models/define_ResNet_1D.py`)

Deep residual network adapted for 1D signal processing with identity and convolutional skip connections.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ResNet50-1D Architecture                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: (batch, 875, 1)                                                     â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  ZeroPadding1D(3) â†’ Conv1D(64, 7, s=2) â†’ BatchNorm â†’ ReLU â†’ MaxPool(3, s=3)â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STAGE 2: [Conv Block + 2Ã— Identity Block]  filters=[64, 64, 256]    â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚   â”‚
â”‚  â”‚   Input â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚   1Ã—1 Conv    â”‚â”€â”€â†’ Add â”€â”€â†’ ReLU â”€â”€â†’ Output     â”‚   â”‚
â”‚  â”‚     â”‚              â”‚   3Ã—3 Conv    â”‚     â†‘                           â”‚   â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚   1Ã—1 Conv    â”‚â”€â”€â”€â”€â”€â”˜                           â”‚   â”‚
â”‚  â”‚                    â”‚   BatchNorm   â”‚  (Identity or 1Ã—1 Conv shortcut)â”‚   â”‚
â”‚  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STAGE 3: [Conv Block + 3Ã— Identity Block]  filters=[128, 128, 512]  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STAGE 4: [Conv Block + 5Ã— Identity Block]  filters=[256, 256, 1024] â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STAGE 5: [Conv Block + 2Ã— Identity Block]  filters=[512, 512, 2048] â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  AveragePooling1D(2) â†’ Flatten                                              â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚     â–¼               â–¼               â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚ SBP  â”‚       â”‚ DBP  â”‚       â”‚  HR  â”‚  (Dense(1, linear) each)           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Residual Block Types:**
| Block Type | Shortcut | Use Case |
|------------|----------|----------|
| Identity Block | Direct connection | Same dimensions |
| Convolutional Block | 1Ã—1 Conv + BN | Dimension change (stride > 1) |

**Key Implementation Details:**
- **Total Blocks**: 16 residual blocks across 5 stages
- **Momentum**: 0.9 for BatchNormalization
- **Stride Pattern**: Downsampling via s=2 in conv blocks

---

#### **3. LSTM** (`models/define_LSTM.py`)

Bidirectional Long Short-Term Memory network for capturing temporal dependencies in physiological signals.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             LSTM Architecture                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: (batch, 875, 1)                                                     â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  Conv1D(64, kernel=5, stride=1, padding='causal', activation='relu')        â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ RECURRENT STAGE                                                      â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  Bidirectional LSTM (128 units, return_sequences=True)              â”‚   â”‚
â”‚  â”‚     â†“                                                                â”‚   â”‚
â”‚  â”‚  Bidirectional LSTM (128 units, return_sequences=True)              â”‚   â”‚
â”‚  â”‚     â†“                                                                â”‚   â”‚
â”‚  â”‚  Bidirectional LSTM (64 units, return_sequences=False)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ DENSE STAGE                                                          â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  Dense(512, relu) â†’ Dense(256, relu) â†’ Dense(128, relu)             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚     â–¼               â–¼                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚  â”‚ SBP  â”‚       â”‚ DBP  â”‚  (Dense(1) each)                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Design Choices:**
- **Causal Convolution**: Ensures no future information leakage
- **Bidirectional Processing**: Captures both forward and backward temporal patterns
- **Effective Receptive Field**: 128Ã—2 = 256 units per direction in early layers

---

#### **4. Slapnicar Model** (`models/slapnicar_model.py`)

Hybrid architecture combining time-domain ResNet with frequency-domain STFT spectrogram features.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Slapnicar Hybrid Architecture                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: (batch, 875, 1)                                                     â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚     â–¼                            â–¼                          â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Signal   â”‚            â”‚   1st Deriv   â”‚         â”‚   2nd Deriv   â”‚       â”‚
â”‚  â”‚  (raw)    â”‚            â”‚   (dt1Ã—fs)    â”‚         â”‚   (dt2Ã—fs)    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚        â”‚                          â”‚                         â”‚               â”‚
â”‚        â–¼                          â–¼                         â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    TIME-DOMAIN BRANCH                               â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  Single-Channel ResNet (4 blocks, 3 conv per block)                â”‚   â”‚
â”‚  â”‚  filters: 32â†’64â†’128 (max 64), kernels: [8, 5, 5, 3]               â”‚   â”‚
â”‚  â”‚  AveragePooling between blocks                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚                                       â”‚
â”‚                                     â–¼                                       â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                              â”‚ GRU(65 units)â”‚                               â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                     â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    FREQUENCY-DOMAIN BRANCH                          â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  STFT (n_fft=64, hop=64) â†’ Magnitude â†’ MagnitudeToDecibel          â”‚   â”‚
â”‚  â”‚     â†“                                                               â”‚   â”‚
â”‚  â”‚  Flatten â†’ Dense(32, relu, L2=0.001) â†’ BatchNorm                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚                                       â”‚
â”‚                                     â–¼                                       â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                           â”‚ Concatenate [time â”‚                             â”‚
â”‚                           â”‚  + frequency]     â”‚                             â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                     â”‚                                       â”‚
â”‚                                     â–¼                                       â”‚
â”‚                     Dense(32, relu) â†’ Dropout(0.25)                        â”‚
â”‚                           â†“                                                 â”‚
â”‚                     Dense(32, relu) â†’ Dropout(0.25)                        â”‚
â”‚                           â†“                                                 â”‚
â”‚                         Flatten                                             â”‚
â”‚                           â”‚                                                 â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                           â”‚
â”‚                     â–¼           â–¼                                           â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚                 â”‚ SBP  â”‚   â”‚ DBP  â”‚  (Dense(1, linear) each)               â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dependencies:**
- **Kapre**: Required for STFT, Magnitude, MagnitudeToDecibel layers
  ```bash
  pip install kapre==0.3.7
  ```

**Key Features:**
- **Multi-branch fusion**: Time + Frequency domain representations
- **Derivative features**: Signal dynamics captured via 1st/2nd order derivatives
- **L2 regularization**: Î»=0.001 on dense layers

---

#### **5. Multi-Task Learning Model** (`multi_task_model.py`)

Shared backbone with task-specific heads for simultaneous BP, HR, and SpO2 prediction.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Multi-Task Learning Architecture                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: (batch, 875, 1)                                                     â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ SHARED BACKBONE (ResNet or Pre-trained)                             â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ Option A: Pre-trained backbone (frozen)                             â”‚   â”‚
â”‚  â”‚   - Load from backbone_path, remove last layer                      â”‚   â”‚
â”‚  â”‚   - backbone.trainable = False                                      â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚ Option B: From scratch                                               â”‚   â”‚
â”‚  â”‚   Conv1D(64,7,s=2) â†’ BN â†’ ReLU â†’ MaxPool(3,s=3)                    â”‚   â”‚
â”‚  â”‚      â†“                                                               â”‚   â”‚
â”‚  â”‚   Residual Block (64 filters)                                       â”‚   â”‚
â”‚  â”‚      â†“                                                               â”‚   â”‚
â”‚  â”‚   Residual Block (128 filters)                                      â”‚   â”‚
â”‚  â”‚      â†“                                                               â”‚   â”‚
â”‚  â”‚   Residual Block (256 filters)                                      â”‚   â”‚
â”‚  â”‚      â†“                                                               â”‚   â”‚
â”‚  â”‚   GlobalAveragePooling1D                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ SHARED DENSE LAYERS                                                 â”‚   â”‚
â”‚  â”‚   Dense(512, relu) â†’ Dropout(0.3) â†’ Dense(256, relu) â†’ Dropout(0.3)â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚     â–¼                  â–¼                  â–¼                  â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ BP HEAD    â”‚   â”‚ BP HEAD    â”‚   â”‚ HR HEAD    â”‚   â”‚SpO2 HEAD   â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚Dense(128)  â”‚   â”‚Dense(128)  â”‚   â”‚Dense(128)  â”‚   â”‚Dense(128)  â”‚         â”‚
â”‚  â”‚Dropout(0.2)â”‚   â”‚Dropout(0.2)â”‚   â”‚Dropout(0.2)â”‚   â”‚Dropout(0.2)â”‚         â”‚
â”‚  â”‚Dense(64)   â”‚   â”‚Dense(64)   â”‚   â”‚Dense(64)   â”‚   â”‚Dense(64)   â”‚         â”‚
â”‚  â”‚     â†“      â”‚   â”‚     â†“      â”‚   â”‚     â†“      â”‚   â”‚     â†“      â”‚         â”‚
â”‚  â”‚   SBP      â”‚   â”‚   DBP      â”‚   â”‚    HR      â”‚   â”‚   SpO2     â”‚         â”‚
â”‚  â”‚(Dense(1))  â”‚   â”‚(Dense(1))  â”‚   â”‚(Dense(1))  â”‚   â”‚(Dense(1))  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                             â”‚
â”‚  Loss Weights: SBP=1.0, DBP=1.0, HR=0.3, SpO2=0.3                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Multi-Task Loss Function:**

$$\mathcal{L}_{total} = w_{sbp} \cdot \mathcal{L}_{sbp} + w_{dbp} \cdot \mathcal{L}_{dbp} + w_{hr} \cdot \mathcal{L}_{hr} + w_{spo2} \cdot \mathcal{L}_{spo2}$$

Where weights are: $w_{sbp}=1.0$, $w_{dbp}=1.0$, $w_{hr}=0.3$, $w_{spo2}=0.3$

---

#### **6. Transformer Model** (`transformer_model.py`) â­ **Best Performance**

Custom Transformer encoder with multi-head self-attention for capturing long-range dependencies.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Transformer Architecture                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: (batch, 875, 1)                                                     â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  Embedding: Dense(d_model=128)                                              â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ POSITIONAL ENCODING                                                  â”‚   â”‚
â”‚  â”‚   PE(pos, 2i) = sin(pos / 10000^(2i/d_model))                       â”‚   â”‚
â”‚  â”‚   PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))                     â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   x = x + PE[:, :seq_len, :]                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  Dropout(0.1)                                                               â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â”‚
â”‚  â•‘              TRANSFORMER ENCODER (Ã— 3 layers)                        â•‘   â”‚
â”‚  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£   â”‚
â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘   â”‚
â”‚  â•‘  â”‚ MULTI-HEAD SELF-ATTENTION (4 heads, depth=32 per head)        â”‚  â•‘   â”‚
â”‚  â•‘  â”‚                                                                â”‚  â•‘   â”‚
â”‚  â•‘  â”‚   Q = x @ W_q    K = x @ W_k    V = x @ W_v                   â”‚  â•‘   â”‚
â”‚  â•‘  â”‚                                                                â”‚  â•‘   â”‚
â”‚  â•‘  â”‚   Attention(Q,K,V) = softmax(QK^T / âˆšd_k) Â· V                 â”‚  â•‘   â”‚
â”‚  â•‘  â”‚                                                                â”‚  â•‘   â”‚
â”‚  â•‘  â”‚   MultiHead = Concat(head_1,...,head_4) @ W_o                 â”‚  â•‘   â”‚
â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘   â”‚
â”‚  â•‘     â”‚                                                                â•‘   â”‚
â”‚  â•‘     â–¼                                                                â•‘   â”‚
â”‚  â•‘  Dropout(0.1) â†’ Add & LayerNorm                                     â•‘   â”‚
â”‚  â•‘     â”‚                                                                â•‘   â”‚
â”‚  â•‘     â–¼                                                                â•‘   â”‚
â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘   â”‚
â”‚  â•‘  â”‚ FEED-FORWARD NETWORK                                          â”‚  â•‘   â”‚
â”‚  â•‘  â”‚   Dense(dff=256, relu) â†’ Dense(d_model=128)                   â”‚  â•‘   â”‚
â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘   â”‚
â”‚  â•‘     â”‚                                                                â•‘   â”‚
â”‚  â•‘     â–¼                                                                â•‘   â”‚
â”‚  â•‘  Dropout(0.1) â†’ Add & LayerNorm                                     â•‘   â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  GlobalAveragePooling1D                                                     â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  Dense(256, relu) â†’ Dropout(0.1) â†’ Dense(128, relu) â†’ Dropout(0.1)         â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚     â–¼               â–¼                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚  â”‚ SBP  â”‚       â”‚ DBP  â”‚  (Dense(1) each)                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Hyperparameters:**
| Parameter | Value | Description |
|-----------|-------|-------------|
| `d_model` | 128 | Model dimension |
| `num_heads` | 4 | Number of attention heads |
| `num_layers` | 3 | Transformer encoder layers |
| `dff` | 256 | Feed-forward dimension |
| `dropout_rate` | 0.1 | Dropout probability |

**Custom Layers (Required for Model Loading):**
```python
from transformer_model import (
    MultiHeadAttention,
    EncoderLayer, 
    TransformerEncoder
)

custom_objects = {
    'MultiHeadAttention': MultiHeadAttention,
    'EncoderLayer': EncoderLayer,
    'TransformerEncoder': TransformerEncoder
}
model = tf.keras.models.load_model('transformer_bp_model.h5', custom_objects=custom_objects)
```

**Why Transformer Achieves Best Results:**
1. **Global context**: Self-attention captures long-range dependencies across entire 7-second window
2. **Efficient representation**: 95% fewer parameters than CNN counterparts
3. **Parallel processing**: No sequential bottleneck like RNNs
4. **Interpretable**: Attention weights show which signal regions influence predictions

---

## ğŸ“ˆ Performance Analysis

### Clinical Validation

```
AAMI Standard (Clinical Threshold):
âœ… SBP: < 10 mmHg MAE
âœ… DBP: < 8 mmHg MAE

Our Results (Transformer):
âœ… SBP: 0.84 mmHg (91.6% better)
âœ… DBP: 0.82 mmHg (89.8% better)

Error Distribution:
ğŸ“Š 95th percentile: < 2.5 mmHg
ğŸ“Š Standard deviation: ~1.0 mmHg
ğŸ“Š Outliers: < 2% of predictions
```

### Model Comparison

| Metric | Domain Adapt. | Multi-Task | Transformer |
|--------|---------------|------------|-------------|
| **Accuracy** |
| SBP MAE | 1.22 mmHg | 0.84 mmHg | 0.84 mmHg |
| DBP MAE | 1.11 mmHg | 0.83 mmHg | 0.82 mmHg |
| **Efficiency** |
| Parameters | 25M | 10M | **463K** |
| Model Size | 62.1 MB | 9.7 MB | **7.7 MB** |
| ONNX Size | N/A | 3.17 MB | **2.29 MB** |
| **Performance** |
| Inference (CPU) | ~50ms | ~30ms | **~20ms** |
| Training Time | ~3 hours | ~1.5 hours | **~2 hours** |
| Best Epoch | 7/50 | 15/20 | **4/25** |

### Dataset Statistics

```
Dataset: UKL rPPG-BP (Preprocessed)
ğŸ“Š Total Samples: 7,851
ğŸ“Š Signal Length: 875 samples (7s @ 125 Hz)
ğŸ“Š Train/Val/Test: 70% / 15% / 15%
ğŸ“Š SBP Range: 90-180 mmHg
ğŸ“Š DBP Range: 60-120 mmHg
```

---

## âš™ï¸ Advanced Usage

### Custom Training Configuration

```python
# train_transformer.py example
python train_transformer.py \
    --epochs 25 \
    --batch-size 32 \
    --d-model 128 \
    --num-heads 4 \
    --num-layers 3 \
    --learning-rate 0.001

# train_multi_task.py example
python train_multi_task.py \
    --epochs 20 \
    --batch-size 32 \
    --loss-weights 1.0 0.3 0.3  # SBP, DBP, HR, SpO2
```

### Model Evaluation

```python
# Visualize results
python visualize_transformer.py        # Generates plots and reports
python visualize_multi_task.py
python visualize_domain_adaptation.py

# Output files in results/:
# - *_predictions.png           : Scatter plots (predicted vs true)
# - *_error_distribution.png    : Error histograms
# - *_summary_report.txt        : Performance metrics
```

### ONNX Deployment

```bash
# Export all models to ONNX
python export_onnx.py

# Output:
# - models/onnx/transformer.onnx    (2.29 MB)
# - models/onnx/multi_task.onnx     (3.17 MB)

# Use with ONNXRuntime:
import onnxruntime as ort
session = ort.InferenceSession('models/onnx/transformer.onnx')
predictions = session.run(None, {'input': signal})
```

---

## ğŸ§ª Testing & Validation

### Real-Time System Tests

```bash
# Full integration test
python test_phase2_step3.py
# Output: Signal quality, BP predictions, processing times

# POS algorithm unit test
python test_pos_only.py
# Validates signal extraction with synthetic data

# Face detection debugging
python debug_face_detection.py
# Tests ROI detection and stabilization
```

### Model Validation

```python
# Evaluate on test set
from tensorflow import keras
import h5py

model = keras.models.load_model('models/transformer_bp_model.h5')
with h5py.File('data/rppg_test.h5', 'r') as f:
    test_x = f['signals'][:]
    test_y = f['labels'][:]

predictions = model.predict(test_x)
mae_sbp = np.mean(np.abs(predictions[:, 0] - test_y[:, 0]))
mae_dbp = np.mean(np.abs(predictions[:, 1] - test_y[:, 1]))
print(f"SBP MAE: {mae_sbp:.2f} mmHg, DBP MAE: {mae_dbp:.2f} mmHg")
```

---

## ğŸ”¬ Signal Processing Algorithms

This section provides comprehensive documentation for all signal processing algorithms implemented in the real-time BP prediction pipeline.

---

### **Algorithm Pipeline Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        REAL-TIME BP PREDICTION PIPELINE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Webcam  â”‚â”€â”€â”€â–¶â”‚ Face Detect  â”‚â”€â”€â”€â–¶â”‚ ROI Extract   â”‚â”€â”€â”€â–¶â”‚ RGB Signal  â”‚  â”‚
â”‚  â”‚ 30 FPS  â”‚    â”‚ (Haar/MP)    â”‚    â”‚ (Forehead)    â”‚    â”‚ Time Series â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚         â”‚
â”‚                                                                  â–¼         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    POS ALGORITHM (pos_algorithm.py)                 â”‚  â”‚
â”‚  â”‚  RGB â†’ Normalize â†’ Orthogonal Projection â†’ Adaptive Weighting       â”‚  â”‚
â”‚  â”‚                          â†“                                          â”‚  â”‚
â”‚  â”‚                    Pulse Signal (rPPG)                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â”‚                                    â”‚
â”‚                                       â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                SIGNAL QUALITY (signal_quality.py)                   â”‚  â”‚
â”‚  â”‚  SNR Analysis â†’ Peak Detection â†’ Frequency Analysis â†’ Quality Score â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â”‚                                    â”‚
â”‚                                       â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    PREPROCESSING PIPELINE                           â”‚  â”‚
â”‚  â”‚  Bandpass Filter â†’ Resample â†’ Normalize (StandardScaler)           â”‚  â”‚
â”‚  â”‚  (0.7-4 Hz)        (â†’125Hz)   (Training mean/scale)                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â”‚                                    â”‚
â”‚                                       â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    MODEL INFERENCE                                  â”‚  â”‚
â”‚  â”‚  Transformer / Multi-Task / ResNet â†’ [SBP_norm, DBP_norm]          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â”‚                                    â”‚
â”‚                                       â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    POST-PROCESSING                                  â”‚  â”‚
â”‚  â”‚  Inverse Transform â†’ Kalman Filter â†’ Physiological Validation      â”‚  â”‚
â”‚  â”‚  (â†’mmHg scale)      (Smoothing)      (SBP > DBP)                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â”‚                                    â”‚
â”‚                                       â–¼                                    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                              â”‚ BP Prediction   â”‚                           â”‚
â”‚                              â”‚ SBP / DBP (mmHg)â”‚                           â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **1. POS Algorithm** (`pos_algorithm.py`)

#### Plane-Orthogonal-to-Skin rPPG Signal Extraction

The POS algorithm extracts pulse signals from RGB video by projecting color variations onto a plane orthogonal to the skin tone vector.

**Reference:**
> Wang, W., et al. "Algorithmic Principles of Remote PPG." IEEE Transactions on Biomedical Engineering, vol. 64, no. 7, pp. 1479-1491, 2017.

#### Mathematical Foundation

**Step 1: Temporal Normalization**
For each sliding window of length $l$ (default: 1.6 seconds):

$$C_n(t) = \frac{C(t)}{\bar{C}}$$

where $C(t) = [R(t), G(t), B(t)]^T$ and $\bar{C}$ is the temporal mean.

**Step 2: Orthogonal Signal Computation**

$$S_1 = G_n - B_n$$
$$S_2 = G_n + B_n - 2R_n$$

**Step 3: Adaptive Alpha Weighting**

$$\alpha = \frac{\sigma(S_1)}{\sigma(S_2)}$$
$$H = S_1 + \alpha \cdot S_2$$

**Implementation:**
```python
class POSExtractor:
    def __init__(self, fs=30, window_size=1.6):
        self.fs = fs
        self.window_samples = int(window_size * fs)  # ~48 samples at 30fps
    
    def pos_algorithm(self, rgb: np.ndarray) -> np.ndarray:
        """
        Extract pulse signal from RGB time series
        
        Args:
            rgb: (N, 3) array - [R, G, B] values per frame
        
        Returns:
            pulse: (N,) array - extracted pulse signal
        """
        N = rgb.shape[0]
        H = np.zeros(N)
        
        for t in range(self.window_samples, N):
            # Extract window
            C = rgb[t-self.window_samples:t, :].T  # (3, window_size)
            
            # Step 1: Temporal normalization
            C_n = C / (np.mean(C, axis=1, keepdims=True) + 1e-10)
            
            # Step 2: Orthogonal projection
            S = np.array([
                C_n[1, :] - C_n[2, :],           # S1 = G - B
                C_n[1, :] + C_n[2, :] - 2*C_n[0, :]  # S2 = G + B - 2R
            ])
            
            # Step 3: Adaptive weighting
            alpha = np.std(S[0]) / (np.std(S[1]) + 1e-10)
            h = S[0] + alpha * S[1]
            
            # Store last sample (sliding window output)
            H[t] = h[-1] - np.mean(h)
        
        return H
```

#### Bandpass Filtering

**Butterworth Filter Parameters:**
| Parameter | Value | Purpose |
|-----------|-------|---------|
| Low cutoff | 0.7 Hz | Remove baseline drift (â‰¥42 BPM) |
| High cutoff | 4.0 Hz | Remove high-freq noise (â‰¤240 BPM) |
| Order | 4 | Sharp rolloff without ringing |
| Type | `filtfilt` | Zero-phase distortion |

---

### **2. Signal Quality Assessment** (`signal_quality.py`)

#### Multi-Metric Quality Scoring System

The `SignalQualityAssessor` class evaluates rPPG signal reliability through multiple complementary metrics.

#### Quality Metrics

| Metric | Weight | Range | Threshold for Good Quality |
|--------|--------|-------|---------------------------|
| **SNR** | 0.4 | -âˆ to +âˆ dB | > 0 dB |
| **Peak Regularity** | 0.3 | 0-1 | > 0.7 |
| **HR Power Ratio** | 0.3 | 0-1 | > 0.3 |

#### SNR Calculation

$$SNR_{dB} = 10 \cdot \log_{10}\left(\frac{P_{signal}}{P_{noise}}\right)$$

where:
- $P_{signal}$ = Power in HR frequency band (0.67-3.0 Hz)
- $P_{noise}$ = Total power - Signal power

**Implementation:**
```python
class SignalQualityAssessor:
    def __init__(self, fs=30):
        self.fs = fs
        self.hr_range = (40, 180)  # BPM
        self.freq_range = (0.67, 3.0)  # Hz (40-180 BPM)
    
    def compute_snr(self, signal: np.ndarray, hr_freq: float) -> float:
        """Compute Signal-to-Noise Ratio in dB"""
        N = len(signal)
        yf = np.fft.fft(signal)
        xf = np.fft.fftfreq(N, 1/self.fs)[:N//2]
        power = np.abs(yf[:N//2])**2
        
        # Signal power: HR frequency Â± 0.1 Hz
        hr_mask = (xf >= hr_freq - 0.1) & (xf <= hr_freq + 0.1)
        signal_power = np.sum(power[hr_mask])
        noise_power = np.sum(power[~hr_mask])
        
        return 10 * np.log10(signal_power / (noise_power + 1e-10))
    
    def assess_quality(self, signal: np.ndarray) -> Tuple[float, dict]:
        """
        Comprehensive signal quality assessment
        
        Returns:
            score: 0-1 quality score
            metrics: dict with detailed metrics
        """
        # Peak detection
        peaks, _ = find_peaks(signal, distance=int(self.fs * 0.4))
        
        # Peak regularity (coefficient of variation inverse)
        if len(peaks) > 1:
            intervals = np.diff(peaks)
            peak_regularity = 1 - (np.std(intervals) / (np.mean(intervals) + 1e-10))
        else:
            peak_regularity = 0
        
        # Frequency domain analysis
        freqs, psd = welch(signal, fs=self.fs)
        hr_mask = (freqs >= self.freq_range[0]) & (freqs <= self.freq_range[1])
        hr_power_ratio = np.sum(psd[hr_mask]) / (np.sum(psd) + 1e-10)
        
        # Dominant HR
        dominant_idx = np.argmax(psd[hr_mask])
        dominant_hr = freqs[hr_mask][dominant_idx] * 60  # BPM
        
        # SNR
        snr = self.compute_snr(signal, dominant_hr / 60)
        
        # Composite score
        score = (
            0.2 * (1 if np.std(signal) > 0.1 else 0) +  # Variability
            0.2 * (1 if len(peaks) >= 3 else 0) +       # Sufficient peaks
            0.2 * (1 if peak_regularity > 0.7 else 0) + # Regular peaks
            0.2 * (1 if hr_power_ratio > 0.3 else 0) +  # HR band dominance
            0.2 * (1 if snr > 0 else 0)                 # Positive SNR
        )
        
        return score, {
            'snr': snr,
            'peak_regularity': peak_regularity,
            'hr_power_ratio': hr_power_ratio,
            'dominant_hr': dominant_hr,
            'num_peaks': len(peaks)
        }
```

---

### **3. BP Stabilization** (`bp_stability.py`)

#### Kalman Filter for Prediction Smoothing

The Kalman filter provides optimal recursive estimation of BP values, reducing prediction jitter while maintaining responsiveness.

#### Kalman Filter Equations

**Prediction Step:**
$$\hat{x}_{k|k-1} = \hat{x}_{k-1|k-1}$$
$$P_{k|k-1} = P_{k-1|k-1} + Q$$

**Update Step:**
$$K_k = \frac{P_{k|k-1}}{P_{k|k-1} + R}$$
$$\hat{x}_{k|k} = \hat{x}_{k|k-1} + K_k(z_k - \hat{x}_{k|k-1})$$
$$P_{k|k} = (1 - K_k)P_{k|k-1}$$

where:
- $Q$ = Process variance (default: 0.1)
- $R$ = Measurement variance (default: 2.0)
- $K_k$ = Kalman gain
- $z_k$ = New measurement

**Implementation:**
```python
class KalmanFilter:
    def __init__(self, process_variance=0.1, measurement_variance=2.0):
        self.Q = process_variance   # Trust in model prediction
        self.R = measurement_variance  # Trust in measurement
        self.estimate = None
        self.error_covariance = 1.0
    
    def update(self, measurement: float) -> float:
        if self.estimate is None:
            self.estimate = measurement
            return measurement
        
        # Prediction
        prediction = self.estimate
        prediction_error = self.error_covariance + self.Q
        
        # Update
        K = prediction_error / (prediction_error + self.R)
        self.estimate = prediction + K * (measurement - prediction)
        self.error_covariance = (1 - K) * prediction_error
        
        return self.estimate


class BPStabilizer:
    def __init__(self, window_size=2, outlier_threshold=4.0):
        self.sbp_kalman = KalmanFilter(process_variance=0.1, measurement_variance=2.0)
        self.dbp_kalman = KalmanFilter(process_variance=0.1, measurement_variance=1.5)
        self.sbp_buffer = deque(maxlen=window_size)
        self.dbp_buffer = deque(maxlen=window_size)
    
    def stabilize(self, sbp: float, dbp: float) -> Tuple[float, float]:
        """
        Stabilize BP predictions using Kalman filtering and outlier rejection
        """
        # Outlier detection (Z-score > 4)
        if len(self.sbp_buffer) >= 3:
            z_sbp = abs(sbp - np.mean(self.sbp_buffer)) / (np.std(self.sbp_buffer) + 1e-10)
            if z_sbp > 4.0:
                sbp = 0.5 * np.mean(list(self.sbp_buffer)[-2:]) + 0.5 * sbp
        
        # Range clipping
        sbp = np.clip(sbp, 70, 200)
        dbp = np.clip(dbp, 40, 130)
        
        # Buffer update
        self.sbp_buffer.append(sbp)
        self.dbp_buffer.append(dbp)
        
        # Simple moving average for smoothness
        sbp_smooth = np.mean(list(self.sbp_buffer)[-2:]) if len(self.sbp_buffer) >= 2 else sbp
        dbp_smooth = np.mean(list(self.dbp_buffer)[-2:]) if len(self.dbp_buffer) >= 2 else dbp
        
        # Physiological validation (SBP must be > DBP)
        if sbp_smooth <= dbp_smooth:
            avg = (sbp_smooth + dbp_smooth) / 2
            sbp_smooth = avg + 10
            dbp_smooth = avg - 10
        
        return sbp_smooth, dbp_smooth
```

---

### **4. Data Preprocessing Pipeline**

#### Training Data Normalization

All models were trained with StandardScaler normalization. **Critical**: Inference must use the same statistics.

**Training Statistics (from `data/rppg_info.txt`):**
```
Label Mean: [143.40, 65.73]  # [SBP_mean, DBP_mean] mmHg
Label Scale: [14.97, 11.30]  # [SBP_std, DBP_std]
```

**Preprocessing Steps:**
1. **Bandpass Filter**: 0.7-4.0 Hz (42-240 BPM)
2. **Resample**: Source FPS â†’ 125 Hz (875 samples for 7s)
3. **Normalize**: $x_{norm} = \frac{x - \mu}{\sigma}$ using training statistics
4. **Reshape**: (875,) â†’ (1, 875, 1) for batch inference

**Inverse Transform (Post-prediction):**
$$BP_{mmHg} = BP_{norm} \times \sigma_{train} + \mu_{train}$$

```python
def load_scaler_stats(info_path='data/rppg_info.txt'):
    """Load training normalization statistics"""
    with open(info_path, 'r') as f:
        for line in f:
            if 'Label Mean' in line:
                label_mean = eval(line.split(': ')[1])
            elif 'Label Scale' in line:
                label_scale = eval(line.split(': ')[1])
    return np.array(label_mean), np.array(label_scale)

def preprocess_signal(signal, fs_source=30, fs_target=125, target_len=875):
    """Complete preprocessing pipeline"""
    # 1. Bandpass filter
    signal = bandpass_filter(signal, fs_source, lowcut=0.7, highcut=4.0)
    
    # 2. Resample to 125 Hz
    signal = scipy.signal.resample(signal, target_len)
    
    # 3. Normalize (zero mean, unit variance)
    signal = (signal - np.mean(signal)) / (np.std(signal) + 1e-10)
    
    # 4. Reshape for model
    return signal.reshape(1, target_len, 1)

def inverse_transform_bp(predictions, label_mean, label_scale):
    """Convert normalized predictions to mmHg"""
    sbp = predictions[0] * label_scale[0] + label_mean[0]
    dbp = predictions[1] * label_scale[1] + label_mean[1]
    return sbp, dbp
```

---

## ğŸ“š Documentation

### Main Documents

- **[PROJECT_FINAL_SUMMARY.md](PROJECT_FINAL_SUMMARY.md)** - Complete project overview with results
- **[README.md](README.md)** - This file (quick start guide)
- **[COMPREHENSIVE_SOLUTION_GUIDE.md](COMPREHENSIVE_SOLUTION_GUIDE.md)** - Detailed technical guide

### Research Papers

**Original Paper:**
```bibtex
@article{schrumpf2021assessment,
  title={Assessment of non-invasive blood pressure prediction from PPG and rPPG signals using deep learning},
  author={Schrumpf, Fabian and Frenzel, Patrick and Aust, Christoph and Osterhoff, Georg and Fuchs, Mirco},
  journal={Sensors},
  volume={21},
  number={18},
  pages={6022},
  year={2021},
  publisher={MDPI}
}
```

**POS Algorithm:**
```bibtex
@article{wang2017algorithmic,
  title={Algorithmic principles of remote PPG},
  author={Wang, Wenjin and den Brinker, Albertus C and Stuijk, Sander and de Haan, Gerard},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={64},
  number={7},
  pages={1479--1491},
  year={2017}
}
```

---

## ğŸ”§ Troubleshooting

### Common Issues

**1. Camera Not Detected**
```bash
# List available cameras
python -c "import cv2; print([cv2.VideoCapture(i).isOpened() for i in range(5)])"

# Try different camera index
python camera_rppg_advanced.py --camera 1
```

**2. Low Signal Quality**
```
Solutions:
- Ensure good lighting (natural light preferred)
- Stay still during measurement
- Position face clearly in frame
- Remove glasses if possible
- Use --duration 10 for longer collection
```

**3. TensorFlow/NumPy Version Conflicts**
```bash
# Reinstall with correct versions
pip uninstall numpy tensorflow
pip install numpy==1.19.5
pip install tensorflow==2.4.1
```

**4. ONNX Export Errors**
```bash
# Install compatible versions
pip install tf2onnx==1.16.1 onnx==1.17.0 onnxruntime==1.19.2
```

### Performance Optimization

```python
# For faster inference, use ONNX Runtime
import onnxruntime as ort
session = ort.InferenceSession(
    'models/onnx/transformer.onnx',
    providers=['CPUExecutionProvider']  # Or 'CUDAExecutionProvider'
)

# Batch processing for multiple signals
predictions = session.run(None, {'input': batch_signals})
```

---

## ğŸ”® Future Work

### Short-term (1-3 months)
- [ ] Model ensemble combining all 3 architectures
- [ ] INT8 quantization for 50% further size reduction
- [ ] Edge TPU optimization for Coral devices
- [ ] Real-time confidence intervals

### Mid-term (3-6 months)
- [ ] Mobile app (Flutter/React Native)
- [ ] Continuous BP monitoring dashboard
- [ ] User-specific fine-tuning
- [ ] Multi-person detection and tracking

### Long-term (6-12 months)
- [ ] Clinical validation study
- [ ] FDA/CE medical device certification
- [ ] Integration with health monitoring systems
- [ ] Commercial product development

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to:

1. **Report Issues**: Found a bug? Open an issue with detailed description
2. **Suggest Features**: Have ideas? Create a feature request
3. **Submit PRs**: Fork, improve, and create a pull request
4. **Share Data**: Have rPPG datasets? Let's collaborate!

### Development Guidelines

```bash
# 1. Fork and clone
git clone https://github.com/YOUR_USERNAME/Yonsei-HCI-LAB-Intern-rPPG-BP-Estimation.git

# 2. Create feature branch
git checkout -b feature/your-feature-name

# 3. Make changes and test
python -m pytest tests/

# 4. Commit with clear messages
git commit -m "Add: Feature description"

# 5. Push and create PR
git push origin feature/your-feature-name
```

---

## ğŸ“œ License

MIT License - see [LICENSE.md](LICENSE.md) for details.

Free to use, modify, and distribute for academic and commercial purposes.

---

## ğŸ™ Acknowledgments

- **Yonsei HCI LAB** - Research environment and support
- **Schrumpf et al.** - Original paper and baseline implementation
- **Wang et al.** - POS algorithm for rPPG extraction
- **UKL Dataset** - High-quality rPPG-BP dataset
- **TensorFlow/Keras** - Deep learning framework
- **OpenCV Community** - Computer vision tools

---

## ğŸ“§ Contact

**Developer**: Resourceful Hooni  
**Affiliation**: Yonsei HCI LAB (Intern)  
**GitHub**: [@resourceful-hooni](https://github.com/resourceful-hooni)  
**Repository**: [Yonsei-HCI-LAB-Intern-rPPG-BP-Estimation](https://github.com/resourceful-hooni/Yonsei-HCI-LAB-Intern-rPPG-BP-Estimation)

For questions, suggestions, or collaboration:
- Open an issue on GitHub
- Star â­ the repo if you find it useful!

---

## ğŸ“Š Project Statistics

```
ï¿½ Total Files: 50+
ğŸ“Š Lines of Code: 15,000+
ğŸ“Š Models Trained: 3 architectures
ğŸ“Š Accuracy: 91.6% better than clinical standard
âš¡ Inference Speed: 20ms (50 FPS capable)
ğŸ“Š Model Size: 2.29 MB (ONNX Transformer)
ğŸ“Š Best MAE: SBP 0.84 mmHg, DBP 0.82 mmHg
```

---

<div align="center">

### ğŸ‰ Project Complete! ğŸŠ

**"Advancing Non-Invasive Healthcare Through AI"**

Made with â¤ï¸ at Yonsei HCI LAB | 2026

[â¬†ï¸ Back to Top](#-non-invasive-blood-pressure-estimation-using-deep-learning)

</div>


